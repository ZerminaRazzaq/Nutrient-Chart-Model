{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nutrient Chart model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "raoRMUU4-iev"
      },
      "source": [
        "#Using KNN \r\n",
        "import pandas as pd\r\n",
        "pd.set_option('display.max_rows', None)\r\n",
        "from numpy import nan\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from pandas import read_csv\r\n",
        "dataset=pd.read_csv(\"/content/nutrients_csvfile.csv\")\r\n",
        "# a list with all missing value formats \r\n",
        "missing_value_formats = [\"n.a\" , \"t\" ,\"t'\" \"a\" , \"?\" , \"--\" , \"n/a\" ]\r\n",
        "dataset = pd.read_csv(\"/content/nutrients_csvfile.csv\", na_values = missing_value_formats)\r\n",
        "#print(dataset.isnull())\r\n",
        "dataset.fillna(dataset.mean(), inplace=True)\r\n",
        "#print(dataset.head(25))\r\n",
        "#dataset =dataset.replace(0,nan)\r\n",
        "\r\n",
        "le=LabelEncoder()\r\n",
        "print(dataset.shape)\r\n",
        "dataset['Food type']=le.fit_transform(dataset['Food'])\r\n",
        "dataset['Quantity']=le.fit_transform(dataset['Measure'])\r\n",
        "#print(dataset.head(25))\r\n",
        "#Delete columns after preprocessing\r\n",
        "del dataset[\"Food\"]\r\n",
        "del dataset[\"Measure\"]\r\n",
        "#del dataset[\"Calories\"]\r\n",
        "#print(dataset.isnull())\r\n",
        "\r\n",
        "print(dataset.head(25))\r\n",
        "X_features_input = dataset.iloc[:, :-1].values #features[rows, columms]\r\n",
        "print(X_features_input)\r\n",
        "y_label_output = dataset.iloc[:, 9].values #labels\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features_input, y_label_output, test_size=0.20, random_state=5)\r\n",
        "#x_train = 80% of our features data(input)\r\n",
        "#x_test = 20% of our features data(input)\r\n",
        "#y_train = 80% of our lable data(output)\r\n",
        "#y_test = 20 % of pur lable data(output)\r\n",
        "#imported the algorithms from library\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\r\n",
        "# to train the model you have to use the function of \"fit()\"\r\n",
        "# while training we only pass the 80 percent of our data\r\n",
        "classifier.fit(X_train,  y_train) # X_train = features #y_train= lable\r\n",
        "# now we have to take prediction on testing data\r\n",
        "y_pred = classifier.predict(X_test) #here we only pass the features\r\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "# print(confusion_matrix(y_test, y_pred))\r\n",
        "#print(classification_report(y_test, y_pred))\r\n",
        "print(y_pred)\r\n",
        "#def evaluate_model(lin_reg,feature,real_label):\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "print('Accuracy Score using KNN: ', accuracy_score(y_pred, y_test)) #y_pred is the output\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "print(confusion_matrix(y_test, y_pred))\r\n",
        "print(classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_metric = f1_score(y_test, y_pred, average = \"macro\")\r\n",
        "#average=\"macro\" it calculates the sperate precision and recall of\r\n",
        "# each class and than take the average of precision and recall. after it calculate the f1 score\r\n",
        "print(\"F1 Score macro:\",f1_metric)\r\n",
        "#\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_metric_micro = f1_score(y_test, y_pred, average = \"micro\")\r\n",
        "print(\"F1 Score Micro:\",f1_metric_micro)\r\n",
        "# for accuracy\r\n",
        "#from sklearn.metrics import accuracy_score\r\n",
        "#print('Accuracy Score: ', accuracy_score(y_pred, y_test)) #y_pred is the output\r\n",
        "\r\n",
        "#Using SVM\r\n",
        "import pandas as pd\r\n",
        "pd.set_option('display.max_rows', None)\r\n",
        "from numpy import nan\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from pandas import read_csv\r\n",
        "dataset=pd.read_csv(\"/content/nutrients_csvfile.csv\")\r\n",
        "# a list with all missing value formats \r\n",
        "missing_value_formats = [\"n.a\" , \"t\" ,\"t'\" \"a\" , \"?\" , \"--\" , \"n/a\" ]\r\n",
        "dataset = pd.read_csv(\"/content/nutrients_csvfile.csv\", na_values = missing_value_formats)\r\n",
        "#print(dataset.isnull())\r\n",
        "dataset.fillna(dataset.mean(), inplace=True)\r\n",
        "#print(dataset.head(25))\r\n",
        "#dataset =dataset.replace(0,nan)\r\n",
        "\r\n",
        "le=LabelEncoder()\r\n",
        "print(dataset.shape)\r\n",
        "dataset['Food type']=le.fit_transform(dataset['Food'])\r\n",
        "dataset['Quantity']=le.fit_transform(dataset['Measure'])\r\n",
        "#print(dataset.head(25))\r\n",
        "#Delete columns after preprocessing\r\n",
        "del dataset[\"Food\"]\r\n",
        "del dataset[\"Measure\"]\r\n",
        "#del dataset[\"Calories\"]\r\n",
        "#print(dataset.isnull())\r\n",
        "\r\n",
        "print(dataset.head(25))\r\n",
        "X_features_input = dataset.iloc[:, :-1].values #features[rows, columms]\r\n",
        "print(X_features_input)\r\n",
        "y_label_output = dataset.iloc[:, 9].values #labels\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features_input, y_label_output, test_size=0.20, random_state=5)\r\n",
        "#x_train = 80% of our features data(input)\r\n",
        "#x_test = 20% of our features data(input)\r\n",
        "#y_train = 80% of our lable data(output)\r\n",
        "#y_test = 20 % of pur lable data(output)\r\n",
        "#imported the algorithms from library\r\n",
        "from sklearn.svm import SVC\r\n",
        "svclassifier = SVC(kernel='linear')\r\n",
        "# to train the model you have to use the function of \"fit()\"\r\n",
        "# while training we only pass the 80 percent of our data\r\n",
        "svclassifier.fit(X_train,  y_train) # X_train = features #y_train= lable\r\n",
        "# now we have to take prediction on testing data\r\n",
        "y_pred = svclassifier.predict(X_test) #here we only pass the features\r\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "# print(confusion_matrix(y_test, y_pred))\r\n",
        "#print(classification_report(y_test, y_pred))\r\n",
        "print(y_pred)\r\n",
        "#def evaluate_model(lin_reg,feature,real_label):\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "print('Accuracy Score score using SVM:  ', accuracy_score(y_pred, y_test)) #y_pred is the output\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "print(confusion_matrix(y_test, y_pred))\r\n",
        "print(classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_metric = f1_score(y_test, y_pred, average = \"macro\")\r\n",
        "#average=\"macro\" it calculates the sperate precision and recall of\r\n",
        "# each class and than take the average of precision and recall. after it calculate the f1 score\r\n",
        "print(\"F1 Score macro:\",f1_metric)\r\n",
        "#\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_metric_micro = f1_score(y_test, y_pred, average = \"micro\")\r\n",
        "print(\"F1 Score Micro:\",f1_metric_micro)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Using Decision Tree\r\n",
        "import pandas as pd\r\n",
        "pd.set_option('display.max_rows', None)\r\n",
        "from numpy import nan\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from pandas import read_csv\r\n",
        "dataset=pd.read_csv(\"/content/nutrients_csvfile.csv\")\r\n",
        "# a list with all missing value formats \r\n",
        "missing_value_formats = [\"n.a\" , \"t\" ,\"t'\" \"a\" , \"?\" , \"--\" , \"n/a\" ]\r\n",
        "dataset = pd.read_csv(\"/content/nutrients_csvfile.csv\", na_values = missing_value_formats)\r\n",
        "#print(dataset.isnull())\r\n",
        "dataset.fillna(dataset.mean(), inplace=True)\r\n",
        "#print(dataset.head(25))\r\n",
        "#dataset =dataset.replace(0,nan)\r\n",
        "\r\n",
        "le=LabelEncoder()\r\n",
        "print(dataset.shape)\r\n",
        "dataset['Food type']=le.fit_transform(dataset['Food'])\r\n",
        "dataset['Quantity']=le.fit_transform(dataset['Measure'])\r\n",
        "#print(dataset.head(25))\r\n",
        "#Delete columns after preprocessing\r\n",
        "del dataset[\"Food\"]\r\n",
        "del dataset[\"Measure\"]\r\n",
        "#del dataset[\"Calories\"]\r\n",
        "#print(dataset.isnull())\r\n",
        "\r\n",
        "print(dataset.head(25))\r\n",
        "X_features_input = dataset.iloc[:, :-1].values #features[rows, columms]\r\n",
        "print(X_features_input)\r\n",
        "y_label_output = dataset.iloc[:, 9].values #labels\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features_input, y_label_output, test_size=0.20, random_state=5)\r\n",
        "#x_train = 80% of our features data(input)\r\n",
        "#x_test = 20% of our features data(input)\r\n",
        "#y_train = 80% of our lable data(output)\r\n",
        "#y_test = 20 % of pur lable data(output)\r\n",
        "#imported the algorithms from library\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "classifier = DecisionTreeClassifier()\r\n",
        "# to train the model you have to use the function of \"fit()\"\r\n",
        "# while training we only pass the 80 percent of our data\r\n",
        "classifier.fit(X_train,  y_train) # X_train = features #y_train= lable\r\n",
        "# now we have to take prediction on testing data\r\n",
        "y_pred = classifier.predict(X_test) #here we only pass the features\r\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "# print(confusion_matrix(y_test, y_pred))\r\n",
        "#print(classification_report(y_test, y_pred))\r\n",
        "print(y_pred)\r\n",
        "#def evaluate_model(lin_reg,feature,real_label):\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "print('Accuracy Score using Decision Tree: ', accuracy_score(y_pred, y_test)) #y_pred is the output\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "print(confusion_matrix(y_test, y_pred))\r\n",
        "print(classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_metric = f1_score(y_test, y_pred, average = \"macro\")\r\n",
        "#average=\"macro\" it calculates the sperate precision and recall of\r\n",
        "# each class and than take the average of precision and recall. after it calculate the f1 score\r\n",
        "print(\"F1 Score macro:\",f1_metric)\r\n",
        "#\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_metric_micro = f1_score(y_test, y_pred, average = \"micro\")\r\n",
        "print(\"F1 Score Micro:\",f1_metric_micro)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Using Naive Bayes\r\n",
        "import pandas as pd\r\n",
        "pd.set_option('display.max_rows', None)\r\n",
        "from numpy import nan\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from pandas import read_csv\r\n",
        "dataset=pd.read_csv(\"/content/nutrients_csvfile.csv\")\r\n",
        "# a list with all missing value formats \r\n",
        "missing_value_formats = [\"n.a\" , \"t\" ,\"t'\" \"a\" , \"?\" , \"--\" , \"n/a\" ]\r\n",
        "dataset = pd.read_csv(\"/content/nutrients_csvfile.csv\", na_values = missing_value_formats)\r\n",
        "#print(dataset.isnull())\r\n",
        "dataset.fillna(dataset.mean(), inplace=True)\r\n",
        "#print(dataset.head(25))\r\n",
        "#dataset =dataset.replace(0,nan)\r\n",
        "\r\n",
        "le=LabelEncoder()\r\n",
        "print(dataset.shape)\r\n",
        "dataset['Food type']=le.fit_transform(dataset['Food'])\r\n",
        "dataset['Quantity']=le.fit_transform(dataset['Measure'])\r\n",
        "#print(dataset.head(25))\r\n",
        "#Delete columns after preprocessing\r\n",
        "del dataset[\"Food\"]\r\n",
        "del dataset[\"Measure\"]\r\n",
        "#del dataset[\"Calories\"]\r\n",
        "#print(dataset.isnull())\r\n",
        "\r\n",
        "print(dataset.head(25))\r\n",
        "X_features_input = dataset.iloc[:, :-1].values #features[rows, columms]\r\n",
        "print(X_features_input)\r\n",
        "y_label_output = dataset.iloc[:, 9].values #labels\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features_input, y_label_output, test_size=0.20, random_state=5)\r\n",
        "#x_train = 80% of our features data(input)\r\n",
        "#x_test = 20% of our features data(input)\r\n",
        "#y_train = 80% of our lable data(output)\r\n",
        "#y_test = 20 % of pur lable data(output)\r\n",
        "#imported the algorithms from library\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "classifier = GaussianNB()\r\n",
        "# to train the model you have to use the function of \"fit()\"\r\n",
        "# while training we only pass the 80 percent of our data\r\n",
        "classifier.fit(X_train,  y_train) # X_train = features #y_train= lable\r\n",
        "# now we have to take prediction on testing data\r\n",
        "y_pred = classifier.predict(X_test) #here we only pass the features\r\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "# print(confusion_matrix(y_test, y_pred))\r\n",
        "#print(classification_report(y_test, y_pred))\r\n",
        "print(y_pred)\r\n",
        "#def evaluate_model(lin_reg,feature,real_label):\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "print('Accuracy Score using Naive Bayes : ', accuracy_score(y_pred, y_test)) #y_pred is the output\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "print(confusion_matrix(y_test, y_pred))\r\n",
        "print(classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_metric = f1_score(y_test, y_pred, average = \"macro\")\r\n",
        "#average=\"macro\" it calculates the sperate precision and recall of\r\n",
        "# each class and than take the average of precision and recall. after it calculate the f1 score\r\n",
        "print(\"F1 Score macro:\",f1_metric)\r\n",
        "#\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_metric_micro = f1_score(y_test, y_pred, average = \"micro\")\r\n",
        "print(\"F1 Score Micro:\",f1_metric_micro)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}